from typing import Dict, List, Tuple, Set, Any, Generator, Optional, Union
import json
from collections import defaultdict, Counter
import math
import os
from tqdm import tqdm

class LayoutAnalyzer:
    def __init__(self, layout_config: Dict[str, Any], layout_name: str = ""):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Ä–∞—Å–∫–ª–∞–¥–∫–∏ —Å —É—á–µ—Ç–æ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        """
        self.layout_name = layout_name
        self.layout_data = layout_config.get("layout", {})
        self.hand_map = {}
        self.finger_map = {}
        self.position_map = {}
        self.column_map = {}
        self.row_map = {}
        self.modifiers_map = {}  # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        
        self._parse_layout()
    
    def _parse_layout(self):
        """–ü–∞—Ä—Å–∏—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ä–∞—Å–∫–ª–∞–¥–∫–∏ –∏ —Å–æ–∑–¥–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥–∏"""
        for letter, data in self.layout_data.items():
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ —Å–ø–∏—Å–æ–∫
            if isinstance(data, dict):
                # –§–æ—Ä–º–∞—Ç 1: —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏
                hand = data.get("hand", "").lower()
                finger = data.get("finger", "")
                row = data.get("row", 0)
                column = data.get("column", 0)
                modifiers = data.get("modifiers", [])
            elif isinstance(data, list):
                # –§–æ—Ä–º–∞—Ç 2: —Å–ø–∏—Å–æ–∫ [hand, finger, row, column, ...modifiers]
                if len(data) >= 4:
                    hand = str(data[0]).lower() if data[0] else ""
                    finger = str(data[1]) if len(data) > 1 else ""
                    row = int(data[2]) if len(data) > 2 else 0
                    column = int(data[3]) if len(data) > 3 else 0
                    modifiers = data[4:] if len(data) > 4 else []
                else:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏
            else:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            
            self.hand_map[letter] = hand
            self.finger_map[letter] = finger
            self.position_map[letter] = (hand, finger, row, column)
            self.column_map[letter] = column
            self.row_map[letter] = row
            self.modifiers_map[letter] = modifiers
    
    def get_finger_order(self, finger: str) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –ø–∞–ª—å—Ü–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        –ú–∏–∑–∏–Ω–µ—Ü = 1, –ë–µ–∑—ã–º—è–Ω–Ω—ã–π = 2, –°—Ä–µ–¥–Ω–∏–π = 3, –£–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π = 4
        """
        finger_mapping = {
            "L1": 1,  # –ú–∏–∑–∏–Ω–µ—Ü –ª–µ–≤—ã–π
            "L2": 2,  # –ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ª–µ–≤—ã–π
            "L3": 3,  # –°—Ä–µ–¥–Ω–∏–π –ª–µ–≤—ã–π
            "L4": 4,  # –£–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –ª–µ–≤—ã–π
            "R1": 4,  # –£–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∞–≤—ã–π
            "R2": 3,  # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∞–≤—ã–π
            "R3": 2,  # –ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–∞–≤—ã–π
            "R4": 1,  # –ú–∏–∑–∏–Ω–µ—Ü –ø—Ä–∞–≤—ã–π
        }
        return finger_mapping.get(finger, 0)
    
    def analyze_character_with_modifiers(self, char: str) -> List[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–º–≤–æ–ª —Å —É—á–µ—Ç–æ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∂–∞—Ç–∏–π –¥–ª—è —Å–∏–º–≤–æ–ª–∞
        """
        if char not in self.modifiers_map:
            return [{
                'char': char,
                'hand': self.hand_map.get(char, ''),
                'finger': self.finger_map.get(char, ''),
                'is_modifier': False,
                'modifier_type': None
            }]
        
        modifiers = self.modifiers_map[char]
        actions = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        for modifier in modifiers:
            if isinstance(modifier, str) and modifier == "shift":
                # Shift –Ω–∞ —Ç–æ–π –∂–µ —Ä—É–∫–µ, —á—Ç–æ –∏ —Å–∏–º–≤–æ–ª
                hand = self.hand_map.get(char, '')
                # –î–ª—è shift –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–∏–∑–∏–Ω–µ—Ü —Ç–æ–π –∂–µ —Ä—É–∫–∏
                shift_finger = "L1" if hand == "left" else "R4"
                actions.append({
                    'char': 'Shift',
                    'hand': hand,
                    'finger': shift_finger,
                    'is_modifier': True,
                    'modifier_type': 'shift'
                })
            elif isinstance(modifier, str) and modifier == "alt":
                # Alt –≤—Å–µ–≥–¥–∞ –ø—Ä–∞–≤–æ–π —Ä—É–∫–æ–π (–æ–±—ã—á–Ω–æ –ø—Ä–∞–≤—ã–º –±–æ–ª—å—à–∏–º –ø–∞–ª—å—Ü–µ–º –∏–ª–∏ –ø—Ä–∞–≤—ã–º –º–∏–∑–∏–Ω—Ü–µ–º)
                actions.append({
                    'char': 'Alt',
                    'hand': 'right',
                    'finger': 'R4',  # –ü—Ä–∞–≤—ã–π –º–∏–∑–∏–Ω–µ—Ü –¥–ª—è Alt
                    'is_modifier': True,
                    'modifier_type': 'alt'
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º —Å–∏–º–≤–æ–ª
        actions.append({
            'char': char,
            'hand': self.hand_map.get(char, ''),
            'finger': self.finger_map.get(char, ''),
            'is_modifier': False,
            'modifier_type': None
        })
        
        return actions
    
    def analyze_sequence_comfort_with_modifiers(self, sequence: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É–¥–æ–±—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        """
        if len(sequence) < 2:
            return {'comfort': 'unknown', 'reason': 'too_short'}
        
        # –î–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ —É—á–µ—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤)
        if len(set(sequence)) == 1:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
            char = sequence[0]
            actions = self.analyze_character_with_modifiers(char)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª –±–µ–∑ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏–ª–∏ —Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –Ω–∞ —Ç–æ–π –∂–µ —Ä—É–∫–µ
            if len(actions) == 1 or all(a['hand'] == actions[0]['hand'] for a in actions):
                return {
                    'comfort': 'comfortable',
                    'reason': 'same_characters',
                    'hand_type': 'single_hand',
                    'sequence': sequence,
                    'length': len(sequence),
                    'has_modifiers': len(actions) > 1
                }
        
        # –†–∞–∑–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –¥–µ–π—Å—Ç–≤–∏—è (—Å —É—á–µ—Ç–æ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤)
        all_actions = []
        for char in sequence:
            if char in self.modifiers_map:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∏–º–≤–æ–ª –µ—Å—Ç—å –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ
                char_actions = self.analyze_character_with_modifiers(char)
                all_actions.extend(char_actions)
            else:
                # –ï—Å–ª–∏ —Å–∏–º–≤–æ–ª–∞ –Ω–µ—Ç –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue
        
        if not all_actions:
            return {'comfort': 'unknown', 'reason': 'no_valid_chars'}
        
        # –£–±–∏—Ä–∞–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–æ–Ω–∏ –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç –¥–ª–∏–Ω—É)
        # –ù–æ —É—á–∏—Ç—ã–≤–∞–µ–º –∏—Ö –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Å–º–µ–Ω—ã —Ä—É–∫–∏
        key_actions = [a for a in all_actions if not a['is_modifier']]
        
        if len(key_actions) < 2:
            return {'comfort': 'unknown', 'reason': 'only_modifiers'}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–º–µ–Ω—É —Ä—É–∫–∏ —Å —É—á–µ—Ç–æ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä—É–∫–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        all_hands = set()
        for action in all_actions:
            if action['hand']:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä—É–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
                all_hands.add(action['hand'])
        
        if not all_hands:
            return {'comfort': 'unknown', 'reason': 'no_hand_info'}
        
        if len(all_hands) > 1:
            # –†–∞–∑–Ω—ã–µ —Ä—É–∫–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤–∫–ª—é—á–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã)
            return {
                'comfort': 'uncomfortable',
                'reason': 'hand_change_with_modifiers',
                'hand_type': 'both',
                'sequence': sequence,
                'length': len(sequence),
                'has_modifiers': any(a['is_modifier'] for a in all_actions)
            }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä—É–∫—É
        hand_type = list(all_hands)[0] if all_hands else 'unknown'
        
        # –î–ª—è –¥–≤—É—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ —É—á–µ—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ –¥–ª–∏–Ω–µ)
        if len(key_actions) == 2:
            action1, action2 = key_actions[0], key_actions[1]
            
            # –ï—Å–ª–∏ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø–∞–ª–µ—Ü - —É–¥–æ–±–Ω–æ
            if action1['finger'] == action2['finger']:
                return {
                    'comfort': 'comfortable',
                    'reason': 'same_finger',
                    'hand_type': hand_type,
                    'sequence': sequence,
                    'length': len(sequence),
                    'has_modifiers': any(a['is_modifier'] for a in all_actions)
                }
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—è–¥–∫–æ–≤—ã–µ –Ω–æ–º–∞—Ä–∞ –ø–∞–ª—å—Ü–µ–≤
            order1 = self.get_finger_order(action1['finger'])
            order2 = self.get_finger_order(action2['finger'])
            
            if order1 == 0 or order2 == 0:
                return {'comfort': 'unknown', 'reason': 'unknown_finger'}
            
            if order1 < order2:
                # –û—Ç –º–∏–∑–∏–Ω—Ü–∞ –∫ —É–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–º—É (–≤–Ω–µ—à–Ω–∏–µ ‚Üí –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ) - –£–î–û–ë–ù–û
                return {
                    'comfort': 'comfortable',
                    'reason': 'outside_to_inside',
                    'hand_type': hand_type,
                    'sequence': sequence,
                    'length': len(sequence),
                    'has_modifiers': any(a['is_modifier'] for a in all_actions)
                }
            else:
                # –û—Ç —É–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫ –º–∏–∑–∏–Ω—Ü—É (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ ‚Üí –≤–Ω–µ—à–Ω–∏–µ) - –ß–ê–°–¢–ò–ß–ù–û –£–î–û–ë–ù–û
                return {
                    'comfort': 'partial',
                    'reason': 'inside_to_outside',
                    'hand_type': hand_type,
                    'sequence': sequence,
                    'length': len(sequence),
                    'has_modifiers': any(a['is_modifier'] for a in all_actions)
                }
        
        # –î–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–∑ 3+ —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ —É—á–µ—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ –¥–ª–∏–Ω–µ)
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –ø–∞–ª—å—Ü—ã —Ä–∞–∑–Ω—ã–µ
            fingers = [action['finger'] for action in key_actions]
            if len(set(fingers)) == 1:
                # –û–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø–∞–ª–µ—Ü –¥–ª—è 3+ —Å–∏–º–≤–æ–ª–æ–≤ - –Ω–µ—É–¥–æ–±–Ω–æ
                return {
                    'comfort': 'uncomfortable',
                    'reason': 'same_finger_multiple',
                    'hand_type': hand_type,
                    'sequence': sequence,
                    'length': len(sequence),
                    'has_modifiers': any(a['is_modifier'] for a in all_actions)
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è
            directions = []
            for i in range(len(key_actions) - 1):
                action1, action2 = key_actions[i], key_actions[i+1]
                order1 = self.get_finger_order(action1['finger'])
                order2 = self.get_finger_order(action2['finger'])
                
                if order1 == 0 or order2 == 0:
                    directions.append('unknown')
                elif order1 < order2:
                    directions.append('outside_to_inside')  # —É–¥–æ–±–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                elif order1 > order2:
                    directions.append('inside_to_outside')  # —á–∞—Å—Ç–∏—á–Ω–æ —É–¥–æ–±–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                else:
                    directions.append('same_finger')
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            if 'unknown' in directions:
                return {'comfort': 'unknown', 'reason': 'unknown_direction'}
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            direction_changes = 0
            for i in range(len(directions) - 1):
                if directions[i] != directions[i+1]:
                    direction_changes += 1
            
            if direction_changes > 0:
                # –°–º–µ–Ω–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è - –ù–ï–£–î–û–ë–ù–û
                return {
                    'comfort': 'uncomfortable',
                    'reason': 'direction_changes',
                    'hand_type': hand_type,
                    'sequence': sequence,
                    'length': len(sequence),
                    'direction_changes': direction_changes,
                    'has_modifiers': any(a['is_modifier'] for a in all_actions)
                }
            else:
                # –í—Å–µ –¥–≤–∏–∂–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
                first_direction = directions[0]
                if first_direction == 'outside_to_inside':
                    # –í—Å–µ –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ç –º–∏–∑–∏–Ω—Ü–∞ –∫ —É–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–º—É - –£–î–û–ë–ù–û
                    return {
                        'comfort': 'comfortable',
                        'reason': 'all_outside_to_inside',
                        'hand_type': hand_type,
                        'sequence': sequence,
                        'length': len(sequence),
                        'has_modifiers': any(a['is_modifier'] for a in all_actions)
                    }
                elif first_direction == 'inside_to_outside':
                    # –í—Å–µ –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ç —É–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫ –º–∏–∑–∏–Ω—Ü—É - –ß–ê–°–¢–ò–ß–ù–û –£–î–û–ë–ù–û
                    return {
                        'comfort': 'partial',
                        'reason': 'all_inside_to_outside',
                        'hand_type': hand_type,
                        'sequence': sequence,
                        'length': len(sequence),
                        'has_modifiers': any(a['is_modifier'] for a in all_actions)
                    }
                else:
                    # –í—Å–µ –Ω–∞ –æ–¥–Ω–æ–º –ø–∞–ª—å—Ü–µ - –Ω–µ—É–¥–æ–±–Ω–æ –¥–ª—è 3+ —Å–∏–º–≤–æ–ª–æ–≤
                    return {
                        'comfort': 'uncomfortable',
                        'reason': 'all_same_finger',
                        'hand_type': hand_type,
                        'sequence': sequence,
                        'length': len(sequence),
                        'has_modifiers': any(a['is_modifier'] for a in all_actions)
                    }
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–æ–¥ analyze_sequence_comfort –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–∏
    def analyze_sequence_comfort(self, sequence: str) -> Dict[str, Any]:
        """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        return self.analyze_sequence_comfort_with_modifiers(sequence)
    
    def calculate_modifier_statistics(self) -> Dict[str, Any]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        """
        modifier_stats = {
            'total_symbols': 0,
            'with_shift': 0,
            'with_alt': 0,
            'with_both': 0,
            'no_modifiers': 0,
            'shift_percent': 0,
            'alt_percent': 0
        }
        
        for letter, modifiers in self.modifiers_map.items():
            modifier_stats['total_symbols'] += 1
            
            if not modifiers:
                modifier_stats['no_modifiers'] += 1
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
                has_shift = any(isinstance(mod, str) and mod == "shift" for mod in modifiers)
                has_alt = any(isinstance(mod, str) and mod == "alt" for mod in modifiers)
                
                if has_shift and has_alt:
                    modifier_stats['with_both'] += 1
                elif has_shift:
                    modifier_stats['with_shift'] += 1
                elif has_alt:
                    modifier_stats['with_alt'] += 1
        
        if modifier_stats['total_symbols'] > 0:
            modifier_stats['shift_percent'] = (modifier_stats['with_shift'] / modifier_stats['total_symbols']) * 100
            modifier_stats['alt_percent'] = (modifier_stats['with_alt'] / modifier_stats['total_symbols']) * 100
        
        return modifier_stats
    
    def analyze_word_sequences(self, word: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ —Å–ª–æ–≤–µ (–æ—Ç 2 –¥–æ 5 —Å–∏–º–≤–æ–ª–æ–≤)
        """
        word = word.strip()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–¥–Ω–æ—Å–∏–º–≤–æ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        if len(word) < 2:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–ª–æ–≤–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–ª–∏—á–∏—è —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ
        valid_chars = []
        for char in word:
            if char in self.position_map:
                valid_chars.append(char)
        
        if len(valid_chars) < 2:
            return None
        
        result = {
            'word': word,
            'word_length': len(word),
            'valid_chars': len(valid_chars),
            'sequences_by_length': {
                2: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0, 'details': []},
                3: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0, 'details': []},
                4: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0, 'details': []},
                5: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0, 'details': []}
            },
            'total_sequences': 0,
            'sequences_with_modifiers': 0
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –¥–ª–∏–Ω
        for seq_len in [2, 3, 4, 5]:
            if len(valid_chars) >= seq_len:
                for i in range(len(valid_chars) - seq_len + 1):
                    sequence = ''.join(valid_chars[i:i + seq_len])
                    analysis = self.analyze_sequence_comfort_with_modifiers(sequence)
                    
                    if analysis['comfort'] != 'unknown':
                        result['sequences_by_length'][seq_len]['total'] += 1
                        result['sequences_by_length'][seq_len][analysis['comfort']] += 1
                        result['sequences_by_length'][seq_len]['details'].append(analysis)
                        result['total_sequences'] += 1
                        
                        if analysis.get('has_modifiers', False):
                            result['sequences_with_modifiers'] += 1
        
        return result
    
    def calculate_finger_load_and_distance(self) -> Dict[str, Any]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ –ø–∞–ª—å—Ü—ã –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
        —Å —É—á–µ—Ç–æ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        """
        finger_counter = Counter()
        finger_positions = defaultdict(list)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º —Å–∏–º–≤–æ–ª–∞–º –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ
        for letter, data in self.layout_data.items():
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
            if isinstance(data, dict):
                finger = data.get("finger", "")
                row = data.get("row", 0)
                column = data.get("column", 0)
                modifiers = data.get("modifiers", [])
            elif isinstance(data, list):
                finger = str(data[1]) if len(data) > 1 else ""
                row = int(data[2]) if len(data) > 2 else 0
                column = int(data[3]) if len(data) > 3 else 0
                modifiers = data[4:] if len(data) > 4 else []
            else:
                continue
            
            if finger:
                # –£—á–∏—Ç—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∏–º–≤–æ–ª
                finger_counter[finger] += 1
                finger_positions[finger].append((row, column, letter, False))
                
                # –£—á–∏—Ç—ã–≤–∞–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
                for modifier in modifiers:
                    if isinstance(modifier, str) and modifier == "shift":
                        # Shift –Ω–∞ —Ç–æ–π –∂–µ —Ä—É–∫–µ
                        if isinstance(data, dict):
                            hand = data.get("hand", "").lower()
                        else:
                            hand = str(data[0]).lower() if data[0] else ""
                        shift_finger = "L1" if hand == "left" else "R4"
                        finger_counter[shift_finger] += 0.5  # Shift —É—á–∏—Ç—ã–≤–∞–µ–º —Å –≤–µ—Å–æ–º 0.5
                    elif isinstance(modifier, str) and modifier == "alt":
                        # Alt –≤—Å–µ–≥–¥–∞ –ø—Ä–∞–≤–æ–π —Ä—É–∫–æ–π
                        finger_counter["R4"] += 0.5  # Alt —É—á–∏—Ç—ã–≤–∞–µ–º —Å –≤–µ—Å–æ–º 0.5
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ –ø–∞–ª—å—Ü—ã
        total_weight = sum(finger_counter.values())
        finger_load = {}
        for finger, weight in finger_counter.items():
            finger_load[finger] = (weight / total_weight * 100) if total_weight > 0 else 0
        
        # –ù–∞—Ö–æ–¥–∏–º –¥–≤–∞ —Å–∞–º—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞–ª—å—Ü–∞
        sorted_fingers = sorted(finger_load.items(), key=lambda x: x[1], reverse=True)
        top_two_load = sum(load for _, load in sorted_fingers[:2])
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–ª—å—Ü–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤)
        max_distances = {}
        for finger, positions in finger_positions.items():
            if len(positions) > 1:
                distances = []
                for i in range(len(positions)):
                    for j in range(i + 1, len(positions)):
                        row1, col1, _, _ = positions[i]
                        row2, col2, _, _ = positions[j]
                        # –ú–∞–Ω—Ö—ç—Ç—Ç–µ–Ω—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                        distance = abs(row2 - row1) + abs(col2 - col1)
                        distances.append(distance)
                max_distances[finger] = max(distances) if distances else 0
            else:
                max_distances[finger] = 0
        
        overall_max_distance = max(max_distances.values()) if max_distances else 0
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é "–ª—É—á—à–µ—Å—Ç—å"
        normalized_load = top_two_load / 100
        normalized_distance = overall_max_distance / 20
        
        goodness_score = normalized_load + normalized_distance
        
        return {
            'finger_load': dict(finger_load),
            'top_two_fingers_load': top_two_load,
            'max_distances': dict(max_distances),
            'overall_max_distance': overall_max_distance,
            'goodness_score': goodness_score,
            'normalized_score': 1 / (1 + goodness_score),
            'modifier_stats': self.calculate_modifier_statistics()
        }
    
    def calculate_comprehensive_analysis(self, wordlist: List[str]) -> Dict[str, Any]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤—Å–µ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤
        """
        total_stats = {
            'layout_name': self.layout_name,
            'by_length': {
                2: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0},
                3: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0},
                4: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0},
                5: {'total': 0, 'comfortable': 0, 'partial': 0, 'uncomfortable': 0}
            },
            'total_sequences': 0,
            'total_words': len(wordlist),
            'words_analyzed': 0,
            'sequences_with_modifiers': 0,
            'sequence_frequencies': {
                'comfortable': Counter(),
                'partial': Counter(),
                'uncomfortable': Counter()
            },
            'comfort_examples': {
                'comfortable': [],
                'partial': [],
                'uncomfortable': []
            },
            'finger_analysis': self.calculate_finger_load_and_distance()
        }
        
        for word in tqdm(wordlist, desc=f"–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–∫–ª–∞–¥–∫–∏ {self.layout_name}"):
            analysis = self.analyze_word_sequences(word)
            
            if analysis is None:
                continue
            
            total_stats['words_analyzed'] += 1
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–ª–∏–Ω–∞–º
            for seq_len in [2, 3, 4, 5]:
                length_data = analysis['sequences_by_length'][seq_len]
                for comfort_type in ['comfortable', 'partial', 'uncomfortable']:
                    total_stats['by_length'][seq_len][comfort_type] += length_data[comfort_type]
                    total_stats['by_length'][seq_len]['total'] += length_data[comfort_type]
            
            total_stats['total_sequences'] += analysis['total_sequences']
            total_stats['sequences_with_modifiers'] += analysis.get('sequences_with_modifiers', 0)
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏ —á–∞—Å—Ç–æ—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —É–¥–æ–±—Å—Ç–≤–∞
            for seq_len in [2, 3, 4, 5]:
                for seq_analysis in analysis['sequences_by_length'][seq_len]['details']:
                    comfort_type = seq_analysis['comfort']
                    seq_str = seq_analysis['sequence']
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã
                    total_stats['sequence_frequencies'][comfort_type][seq_str] += 1
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
                    if seq_str not in [ex['sequence'] for ex in total_stats['comfort_examples'][comfort_type]]:
                        if len(total_stats['comfort_examples'][comfort_type]) < 10:
                            total_stats['comfort_examples'][comfort_type].append(seq_analysis)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        for seq_len in [2, 3, 4, 5]:
            total = total_stats['by_length'][seq_len]['total']
            if total > 0:
                for comfort_type in ['comfortable', 'partial', 'uncomfortable']:
                    count = total_stats['by_length'][seq_len][comfort_type]
                    total_stats['by_length'][seq_len][f'{comfort_type}_percent'] = (count / total) * 100
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_comfortable = sum(total_stats['by_length'][l]['comfortable'] for l in [2, 3, 4, 5])
        total_partial = sum(total_stats['by_length'][l]['partial'] for l in [2, 3, 4, 5])
        total_uncomfortable = sum(total_stats['by_length'][l]['uncomfortable'] for l in [2, 3, 4, 5])
        
        total_stats['overall'] = {
            'comfortable': total_comfortable,
            'partial': total_partial,
            'uncomfortable': total_uncomfortable,
            'total': total_stats['total_sequences'],
            'comfortable_percent': (total_comfortable / total_stats['total_sequences'] * 100) if total_stats['total_sequences'] > 0 else 0,
            'partial_percent': (total_partial / total_stats['total_sequences'] * 100) if total_stats['total_sequences'] > 0 else 0,
            'uncomfortable_percent': (total_uncomfortable / total_stats['total_sequences'] * 100) if total_stats['total_sequences'] > 0 else 0,
            'modifiers_percent': (total_stats['sequences_with_modifiers'] / total_stats['total_sequences'] * 100) if total_stats['total_sequences'] > 0 else 0
        }
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
        for comfort_type in ['comfortable', 'partial', 'uncomfortable']:
            total_stats[f'top_{comfort_type}_sequences'] = dict(
                sorted(total_stats['sequence_frequencies'][comfort_type].items(), 
                      key=lambda x: x[1], reverse=True)[:20]
            )
        
        del total_stats['sequence_frequencies']
        
        return total_stats
    
    def prepare_plot_data(self, comprehensive_stats: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        """
        plot_data = {
            'layout_name': self.layout_name,
            'by_length': {
                'lengths': ['2 —Å–∏–º–≤–æ–ª–∞', '3 —Å–∏–º–≤–æ–ª–∞', '4 —Å–∏–º–≤–æ–ª–∞', '5 —Å–∏–º–≤–æ–ª–æ–≤'],
                'comfortable': [],
                'partial': [],
                'uncomfortable': [],
                'comfortable_percent': [],
                'partial_percent': [],
                'uncomfortable_percent': [],
                'total': []
            },
            'overall_stats': {
                'comfortable': comprehensive_stats['overall']['comfortable'],
                'partial': comprehensive_stats['overall']['partial'],
                'uncomfortable': comprehensive_stats['overall']['uncomfortable'],
                'comfortable_percent': comprehensive_stats['overall']['comfortable_percent'],
                'partial_percent': comprehensive_stats['overall']['partial_percent'],
                'uncomfortable_percent': comprehensive_stats['overall']['uncomfortable_percent'],
                'modifiers_percent': comprehensive_stats['overall']['modifiers_percent'],
                'total_sequences': comprehensive_stats['overall']['total']
            },
            'finger_analysis': comprehensive_stats['finger_analysis'],
            'examples': comprehensive_stats['comfort_examples'],
            'top_sequences': {
                'comfortable': comprehensive_stats.get('top_comfortable_sequences', {}),
                'partial': comprehensive_stats.get('top_partial_sequences', {}),
                'uncomfortable': comprehensive_stats.get('top_uncomfortable_sequences', {})
            },
            'word_stats': {
                'total_words': comprehensive_stats['total_words'],
                'words_analyzed': comprehensive_stats['words_analyzed'],
                'analysis_percent': (comprehensive_stats['words_analyzed'] / comprehensive_stats['total_words'] * 100) 
                                   if comprehensive_stats['total_words'] > 0 else 0
            }
        }
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–ª–∏–Ω–∞–º
        for length in [2, 3, 4, 5]:
            data = comprehensive_stats['by_length'][length]
            plot_data['by_length']['comfortable'].append(data['comfortable'])
            plot_data['by_length']['partial'].append(data['partial'])
            plot_data['by_length']['uncomfortable'].append(data['uncomfortable'])
            plot_data['by_length']['comfortable_percent'].append(data.get('comfortable_percent', 0))
            plot_data['by_length']['partial_percent'].append(data.get('partial_percent', 0))
            plot_data['by_length']['uncomfortable_percent'].append(data.get('uncomfortable_percent', 0))
            plot_data['by_length']['total'].append(data['total'])
        
        return plot_data


def load_layout_from_json(file_path: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ä–∞—Å–∫–ª–∞–¥–∫–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def read_words_by_lines(file_path: str, batch_size: int = 1000, 
                       encoding: str = 'utf-8') -> Generator[List[str], None, None]:
    """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞—è –±–∞—Ç—á–∏ —Å–ª–æ–≤"""
    current_batch = []
    
    with open(file_path, 'r', encoding=encoding) as f:
        for line in f:
            line = line.strip()
            if line:
                words = line.split()
                current_batch.extend(words)
                
                if len(current_batch) >= batch_size:
                    yield current_batch
                    current_batch = []
    
    if current_batch:
        yield current_batch

def count_lines_in_file(file_path: str, encoding: str = 'utf-8') -> int:
    """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ"""
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            return sum(1 for _ in f)
    except:
        return 0

def analyze_layout_comprehensive(layout_config: Dict[str, Any], 
                               layout_name: str,
                               file_path: str,
                               max_samples: int = 100000) -> Dict[str, Any]:
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–∫–ª–∞–¥–∫–∏
    """
    analyzer = LayoutAnalyzer(layout_config, layout_name)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    words_for_analysis = []
    word_generator = read_words_by_lines(file_path, batch_size=1000, encoding='utf-8')
    
    total_words = count_lines_in_file(file_path, encoding='utf-8')
    pbar = tqdm(total=min(total_words, max_samples), desc=f"–°–±–æ—Ä —Å–ª–æ–≤ –¥–ª—è {layout_name}")
    
    try:
        for batch in word_generator:
            for word in batch:
                if len(words_for_analysis) < max_samples:
                    word = word.strip()
                    if len(word) >= 2:
                        words_for_analysis.append(word)
                        pbar.update(1)
                
                if len(words_for_analysis) >= max_samples:
                    break
            if len(words_for_analysis) >= max_samples:
                break
    finally:
        pbar.close()
    
    print(f"\nüìä –î–ª—è —Ä–∞—Å–∫–ª–∞–¥–∫–∏ '{layout_name}':")
    print(f"   ‚Ä¢ –°–æ–±—Ä–∞–Ω–æ —Å–ª–æ–≤: {len(words_for_analysis):,}")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    comprehensive_stats = analyzer.calculate_comprehensive_analysis(words_for_analysis)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    plot_data = analyzer.prepare_plot_data(comprehensive_stats)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = {
        'layout_name': layout_name,
        'file_analyzed': os.path.basename(file_path),
        'total_words_in_file': total_words,
        'words_analyzed': len(words_for_analysis),
        'comprehensive_stats': comprehensive_stats,
        'plot_data': plot_data,
        'goodness_score': comprehensive_stats['finger_analysis']['goodness_score'],
        'normalized_score': comprehensive_stats['finger_analysis']['normalized_score']
    }
    
    return result

def print_analysis_summary(result):
    """
    –í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–∫—É –∞–Ω–∞–ª–∏–∑–∞
    """
    layout_name = result['layout_name']
    plot_data = result['plot_data']
    finger_analysis = result['comprehensive_stats']['finger_analysis']
    modifier_stats = finger_analysis.get('modifier_stats', {})
    
    print("\n" + "=" * 80)
    print(f"–ê–ù–ê–õ–ò–ó –†–ê–°–ö–õ–ê–î–ö–ò: {layout_name}")
    print("=" * 80)
    
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  ‚Ä¢ –§–∞–π–ª: {result['file_analyzed']}")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å–ª–æ–≤ –≤ —Ñ–∞–π–ª–µ: {result['total_words_in_file']:,}")
    print(f"  ‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–ª–æ–≤: {result['words_analyzed']:,}")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {plot_data['overall_stats']['total_sequences']:,}")
    
    print(f"\nüèÜ –õ–£–ß–®–ï–°–¢–¨ –†–ê–°–ö–õ–ê–î–ö–ò (–ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é '–ø—É—Ç—å –ø–∞–ª—å—Ü–∞'):")
    print(f"  ‚Ä¢ –ù–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ –¥–≤–∞ —Å–∞–º—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞–ª—å—Ü–∞: {finger_analysis['top_two_fingers_load']:.1f}%")
    print(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—É—Ç—å –ø–∞–ª—å—Ü–∞: {finger_analysis['overall_max_distance']:.2f}")
    print(f"  ‚Ä¢ Goodness Score: {finger_analysis['goodness_score']:.4f}")
    print(f"  ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π Score (—á–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –ª—É—á—à–µ): {finger_analysis['normalized_score']:.4f}")
    
    print(f"\nüéØ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ò–§–ò–ö–ê–¢–û–†–ê–ú:")
    if modifier_stats:
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ä–∞—Å–∫–ª–∞–¥–∫–µ: {modifier_stats['total_symbols']}")
        print(f"  ‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤ —Å Shift: {modifier_stats['with_shift']} ({modifier_stats['shift_percent']:.1f}%)")
        print(f"  ‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤ —Å Alt: {modifier_stats['with_alt']} ({modifier_stats['alt_percent']:.1f}%)")
        print(f"  ‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤ —Å –æ–±–æ–∏–º–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏: {modifier_stats['with_both']}")
        print(f"  ‚Ä¢ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏: {plot_data['overall_stats']['modifiers_percent']:.1f}%")
    
    print(f"\nüìà –û–ë–©–ê–Ø –£–î–û–ë–ù–û–°–¢–¨ –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô:")
    print(f"  ‚Ä¢ –£–¥–æ–±–Ω—ã–µ: {plot_data['overall_stats']['comfortable']:,} ({plot_data['overall_stats']['comfortable_percent']:.1f}%)")
    print(f"  ‚Ä¢ –ß–∞—Å—Ç–∏—á–Ω–æ —É–¥–æ–±–Ω—ã–µ: {plot_data['overall_stats']['partial']:,} ({plot_data['overall_stats']['partial_percent']:.1f}%)")
    print(f"  ‚Ä¢ –ù–µ—É–¥–æ–±–Ω—ã–µ: {plot_data['overall_stats']['uncomfortable']:,} ({plot_data['overall_stats']['uncomfortable_percent']:.1f}%)")
    
    print(f"\nüìè –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –î–õ–ò–ù–ê–ú –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô:")
    for i, length_name in enumerate(plot_data['by_length']['lengths']):
        print(f"  ‚Ä¢ {length_name}:")
        print(f"      –£–¥–æ–±–Ω—ã–µ: {plot_data['by_length']['comfortable'][i]:,} ({plot_data['by_length']['comfortable_percent'][i]:.1f}%)")
        print(f"      –ß–∞—Å—Ç–∏—á–Ω–æ —É–¥–æ–±–Ω—ã–µ: {plot_data['by_length']['partial'][i]:,} ({plot_data['by_length']['partial_percent'][i]:.1f}%)")
        print(f"      –ù–µ—É–¥–æ–±–Ω—ã–µ: {plot_data['by_length']['uncomfortable'][i]:,} ({plot_data['by_length']['uncomfortable_percent'][i]:.1f}%)")
        print(f"      –í—Å–µ–≥–æ: {plot_data['by_length']['total'][i]:,}")
    
    print(f"\nüëÜ –ù–ê–ì–†–£–ó–ö–ê –ù–ê –ü–ê–õ–¨–¶–´:")
    for finger, load in finger_analysis['finger_load'].items():
        print(f"  ‚Ä¢ {finger}: {load:.1f}%")
    
    # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —É–¥–æ–±—Å—Ç–≤–∞
    for comfort_type, comfort_name in [('comfortable', '–£–¥–æ–±–Ω—ã–µ'), ('partial', '–ß–∞—Å—Ç–∏—á–Ω–æ —É–¥–æ–±–Ω—ã–µ'), ('uncomfortable', '–ù–µ—É–¥–æ–±–Ω—ã–µ')]:
        examples = plot_data['examples'].get(comfort_type, [])
        if examples:
            print(f"\n{'‚úÖ' if comfort_type == 'comfortable' else '‚ö†Ô∏è' if comfort_type == 'partial' else '‚ùå'} –ü–†–ò–ú–ï–†–´ {comfort_name.upper()} –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô:")
            for example in examples[:3]:
                has_mod = example.get('has_modifiers', False)
                mod_info = " (—Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏)" if has_mod else ""
                reason_map = {
                    'outside_to_inside': '–≤–Ω–µ—à–Ω–∏–µ‚Üí–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ',
                    'inside_to_outside': '–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ‚Üí–≤–Ω–µ—à–Ω–∏–µ',
                    'same_finger': '–æ–¥–∏–Ω –ø–∞–ª–µ—Ü',
                    'hand_change_with_modifiers': '—Å–º–µ–Ω–∞ —Ä—É–∫–∏ (—Å –º–æ–¥–∏—Ñ.)',
                    'direction_changes': '—Å–º–µ–Ω–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è',
                    'same_characters': '–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã'
                }
                reason = reason_map.get(example.get('reason', ''), example.get('reason', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                print(f"  ‚Ä¢ '{example['sequence']}' ({example['length']} —Å–∏–º–≤–æ–ª–∞){mod_info} - {reason}")
    
    print(f"\nüèÜ –¢–û–ü-3 –°–ê–ú–´–• –ß–ê–°–¢–´–• –£–î–û–ë–ù–´–• –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô:")
    top_comfortable = list(plot_data['top_sequences']['comfortable'].items())[:3]
    for i, (seq, freq) in enumerate(top_comfortable, 1):
        print(f"  {i}. '{seq}': {freq:,} —Ä–∞–∑")
    
    print(f"\nüèÜ –¢–û–ü-3 –°–ê–ú–´–• –ß–ê–°–¢–´–• –ß–ê–°–¢–ò–ß–ù–û –£–î–û–ë–ù–´–• –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô:")
    top_partial = list(plot_data['top_sequences']['partial'].items())[:3]
    for i, (seq, freq) in enumerate(top_partial, 1):
        print(f"  {i}. '{seq}': {freq:,} —Ä–∞–∑")
    
    print("\n" + "=" * 80)
    print("–ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 80)

def save_analysis_results(result, output_dir: str = "analysis_results"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ JSON —Ñ–∞–π–ª —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ä–∞—Å–∫–ª–∞–¥–∫–∏"""
    os.makedirs(output_dir, exist_ok=True)
    
    layout_name = result['layout_name']
    # –£–±–∏—Ä–∞–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    safe_name = "".join(c for c in layout_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
    output_file = os.path.join(output_dir, f"{safe_name}_analysis.json")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    return output_file

def analyze_multiple_layouts(layout_files: List[Tuple[str, str]], 
                           text_file: str,
                           max_samples_per_layout: int = 100000) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞—Å–∫–ª–∞–¥–æ–∫ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    """
    all_results = {}
    comparison_data = {
        'layouts': [],
        'by_length_comparison': {
            2: {'layouts': [], 'comfortable': [], 'partial': [], 'uncomfortable': []},
            3: {'layouts': [], 'comfortable': [], 'partial': [], 'uncomfortable': []},
            4: {'layouts': [], 'comfortable': [], 'partial': [], 'uncomfortable': []},
            5: {'layouts': [], 'comfortable': [], 'partial': [], 'uncomfortable': []}
        },
        'goodness_scores': [],
        'overall_comfort': {'layouts': [], 'comfortable': [], 'partial': [], 'uncomfortable': []},
        'modifier_stats': [],
        'text_file': os.path.basename(text_file),
        'total_words_analyzed': 0
    }
    
    for layout_file, layout_name in layout_files:
        print(f"\n{'='*60}")
        print(f"–ù–ê–ß–ò–ù–ê–ï–ú –ê–ù–ê–õ–ò–ó –†–ê–°–ö–õ–ê–î–ö–ò: {layout_name}")
        print(f"{'='*60}")
        
        try:
            layout_config = load_layout_from_json(layout_file)
            result = analyze_layout_comprehensive(
                layout_config, 
                layout_name, 
                text_file,
                max_samples_per_layout
            )
            
            all_results[layout_name] = result
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            comparison_data['layouts'].append(layout_name)
            comparison_data['total_words_analyzed'] += result['words_analyzed']
            
            # –î–∞–Ω–Ω—ã–µ –ø–æ –¥–ª–∏–Ω–∞–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            for length in [2, 3, 4, 5]:
                plot_data = result['plot_data']
                idx = list(plot_data['by_length']['lengths']).index(f'{length} —Å–∏–º–≤–æ–ª–∞' if length != 5 else '5 —Å–∏–º–≤–æ–ª–æ–≤')
                
                comparison_data['by_length_comparison'][length]['layouts'].append(layout_name)
                comparison_data['by_length_comparison'][length]['comfortable'].append(
                    plot_data['by_length']['comfortable_percent'][idx]
                )
                comparison_data['by_length_comparison'][length]['partial'].append(
                    plot_data['by_length']['partial_percent'][idx]
                )
                comparison_data['by_length_comparison'][length]['uncomfortable'].append(
                    plot_data['by_length']['uncomfortable_percent'][idx]
                )
            
            # –û–±—â–∞—è —É–¥–æ–±–Ω–æ—Å—Ç—å
            comparison_data['overall_comfort']['layouts'].append(layout_name)
            comparison_data['overall_comfort']['comfortable'].append(
                result['plot_data']['overall_stats']['comfortable_percent']
            )
            comparison_data['overall_comfort']['partial'].append(
                result['plot_data']['overall_stats']['partial_percent']
            )
            comparison_data['overall_comfort']['uncomfortable'].append(
                result['plot_data']['overall_stats']['uncomfortable_percent']
            )
            
            # Goodness scores
            comparison_data['goodness_scores'].append({
                'layout': layout_name,
                'score': result['goodness_score'],
                'normalized': result['normalized_score'],
                'top_two_load': result['comprehensive_stats']['finger_analysis']['top_two_fingers_load'],
                'max_distance': result['comprehensive_stats']['finger_analysis']['overall_max_distance']
            })
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º
            modifier_stats = result['comprehensive_stats']['finger_analysis'].get('modifier_stats', {})
            comparison_data['modifier_stats'].append({
                'layout': layout_name,
                'shift_percent': modifier_stats.get('shift_percent', 0),
                'alt_percent': modifier_stats.get('alt_percent', 0),
                'sequences_with_modifiers': result['plot_data']['overall_stats'].get('modifiers_percent', 0)
            })
            
            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
            print_analysis_summary(result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            save_analysis_results(result)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–∞—Å–∫–ª–∞–¥–∫–∏ {layout_name}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_file = os.path.join("analysis_results", "layout_comparison.json")
    with open(comparison_file, 'w', encoding='utf-8') as f:
        json.dump(comparison_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {comparison_file}")
    
    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    print("\n" + "="*80)
    print("–ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –†–ê–°–ö–õ–ê–î–û–ö")
    print("="*80)
    
    if comparison_data['goodness_scores']:
        print("\nüèÜ –†–ï–ô–¢–ò–ù–ì –†–ê–°–ö–õ–ê–î–û–ö (—á–µ–º –º–µ–Ω—å—à–µ goodness score, —Ç–µ–º –ª—É—á—à–µ):")
        sorted_scores = sorted(comparison_data['goodness_scores'], key=lambda x: x['score'])
        for i, score_data in enumerate(sorted_scores, 1):
            print(f"{i}. {score_data['layout']}:")
            print(f"   ‚Ä¢ Goodness Score: {score_data['score']:.4f}")
            print(f"   ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π: {score_data['normalized']:.4f}")
            print(f"   ‚Ä¢ –ù–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ 2 –ø–∞–ª—å—Ü–∞: {score_data['top_two_load']:.1f}%")
            print(f"   ‚Ä¢ –ú–∞–∫—Å. —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {score_data['max_distance']:.2f}")
    
    if comparison_data['modifier_stats']:
        print("\nüéØ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ò–§–ò–ö–ê–¢–û–†–ê–ú:")
        for stats in comparison_data['modifier_stats']:
            print(f"  ‚Ä¢ {stats['layout']}: Shift={stats['shift_percent']:.1f}%, Alt={stats['alt_percent']:.1f}%, –ü–æ—Å–ª–µ–¥. —Å –º–æ–¥–∏—Ñ.={stats['sequences_with_modifiers']:.1f}%")
    
    return {
        'individual_results': all_results,
        'comparison_data': comparison_data
    }

if __name__ == "__main__":
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å–∫–ª–∞–¥–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    LAYOUTS = [
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/–π—Ü—É–∫–µ–Ω (2).json", "–ô–¶–£–ö–ï–ù (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è)"),
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/ant (4).json", "–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ä–∞—Å–∫–ª–∞–¥–∫–∞"),
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/rusphone (2).json","—Ä—É—Å—Ñ–æ–Ω"),
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/zubachew.json","–∑—É–±–∞—á–µ–≤"),
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/skoropis (2).json","—Å–∫–æ—Ä–æ–ø–∏—Å—å"),
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/diktor (2).json","–¥–∏–∫—Ç–æ—Ä"),
        ("/Users/evgenii/Develop/py_proj/tr/KVA/example_layouts/keyboardFINAL (1).json","–í—ã–∑–æ–≤"),
        # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ —Ä–∞—Å–∫–ª–∞–¥–∫–∏ –∑–¥–µ—Å—å
    ]
    
    # –§–∞–π–ª —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    TEXT_FILE = "/Users/evgenii/Develop/py_proj/tr/KVA/1grams-3.txt"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Ä–∞—Å–∫–ª–∞–¥–æ–∫
    valid_layouts = []
    for layout_file, layout_name in LAYOUTS:
        if os.path.exists(layout_file):
            valid_layouts.append((layout_file, layout_name))
        else:
            print(f"‚ö†Ô∏è  –§–∞–π–ª —Ä–∞—Å–∫–ª–∞–¥–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {layout_file}")
    
    if not valid_layouts:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –≤–∞–ª–∏–¥–Ω–æ–π —Ä–∞—Å–∫–ª–∞–¥–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    else:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ä–∞—Å–∫–ª–∞–¥–∫–∏
        results = analyze_multiple_layouts(
            valid_layouts,
            TEXT_FILE,
            max_samples_per_layout=500000  
        )
        
        print("\nüéØ –ê–ù–ê–õ–ò–ó –í–°–ï–• –†–ê–°–ö–õ–ê–î–û–ö –ó–ê–í–ï–†–®–ï–ù!")